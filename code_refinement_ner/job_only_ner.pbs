#!/bin/bash
#PBS -l walltime=60:00:00,select=1:ncpus=8:mem=48gb:ngpus=1:gpu_mem=32gb
#PBS -N mm-trans
#PBS -A st-fhendija-1-gpu
#PBS -o outputTestMem.txt
#PBS -e errorTestMem.txt

########################################################################

cd $PBS_O_WORKDIR



lang=java #programming language
output_dir=model/$lang
pretrained_model=/scratch/st-fhendija-1/iman/pre-trained/models/microsoft/codebert-base    #microsoft/codebert-base Roberta: roberta-base
data_size=small

python run_only_ner.py \
	--do_train \
	--do_eval \
	--model_type roberta \
	--model_name_or_path $pretrained_model \
	--config_name  $pretrained_model \
	--tokenizer_name  $pretrained_model \
	--train_filename ../data/$data_size/train.buggy-fixed.buggy,../data/$data_size/train.buggy-fixed.fixed \
	--dev_filename ../data/$data_size/valid.buggy-fixed.buggy,../data/$data_size/valid.buggy-fixed.fixed \
	--output_dir $output_dir \
	--max_source_length 256 \
	--max_target_length 256 \
	--beam_size 5 \
	--train_batch_size 16 \
	--eval_batch_size 16 \
	--learning_rate 5e-5 \
	--train_steps 100000 \
	--eval_steps 5000 \
        2>&1 | tee only_ner_log_{$lang}.log 
